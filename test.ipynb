{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## path 탐색 / 디렉터리 내부 파일 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test2.pt', 'test3.pt', 'yolov8n.pt', 'test1.pt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir(\"weights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bhc/Desktop/dev/evc-switch-predictor\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'YOLOv8': ['test2.pt', 'test3.pt', 'yolov8n.pt', 'test1.pt']}\n"
     ]
    }
   ],
   "source": [
    "w_list = os.listdir(\"weights/\")\n",
    "model_map = {\n",
    "    \"YOLOv8\" : w_list\n",
    "}\n",
    "\n",
    "print(model_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RTSP 데이터 가공 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhc/opt/anaconda3/envs/edge-fw/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeVideo(url):\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "    currenttime = datetime.datetime.now()\n",
    "    video_capture = cv2.VideoCapture(url)\n",
    "    \n",
    "    video_capture.set(3, 120)\n",
    "    video_capture.set(4, 120)\n",
    "    fps = 20\n",
    "\n",
    "    streaming_window_width = int(video_capture.get(3))\n",
    "    streaming_window_height = int(video_capture.get(4))\n",
    "\n",
    "    filename = str(currenttime.strftime('%Y %m %d %H %M %S'))\n",
    "    path = os.getcwd() + \"/stream/\" + f\"{filename}.mp4\"\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'h264')\n",
    "    out = cv2.VideoWriter(path, fourcc, fps, (streaming_window_width, streaming_window_height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        results = model(frame)\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        cv2.imshow(\"streaming video\", annotated_frame)\n",
    "        out.write(annotated_frame)\n",
    "\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'rtsp://user1:ketiabcs@evc.re.kr:39091/h264Preview_01_main'\n",
    "\n",
    "writeVideo(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x34363268/'h264' is not supported with codec id 27 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x31637661/'avc1'\n",
      "\n",
      "0: 384x640 1 person, 66.4ms\n",
      "Speed: 2.6ms preprocess, 66.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bhc/opt/anaconda3/envs/edge-fw/lib/python3.8/site-packages/gradio/queueing.py\", line 406, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/Users/bhc/opt/anaconda3/envs/edge-fw/lib/python3.8/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/bhc/opt/anaconda3/envs/edge-fw/lib/python3.8/site-packages/gradio/blocks.py\", line 1554, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/bhc/opt/anaconda3/envs/edge-fw/lib/python3.8/site-packages/gradio/blocks.py\", line 1192, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/bhc/opt/anaconda3/envs/edge-fw/lib/python3.8/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/Users/bhc/opt/anaconda3/envs/edge-fw/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/bhc/opt/anaconda3/envs/edge-fw/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/bhc/opt/anaconda3/envs/edge-fw/lib/python3.8/site-packages/gradio/utils.py\", line 659, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/9c/d9bwhd_11tqdj2jhtjf0wmh80000gn/T/ipykernel_28862/1739053112.py\", line 5, in view\n",
      "    return writeVideo(url)\n",
      "  File \"/var/folders/9c/d9bwhd_11tqdj2jhtjf0wmh80000gn/T/ipykernel_28862/2456347041.py\", line 24, in writeVideo\n",
      "    cv2.imshow(\"streaming video\", annotated_frame)\n",
      "cv2.error: Unknown C++ exception from OpenCV code\n"
     ]
    }
   ],
   "source": [
    "## use gradio\n",
    "url = 'rtsp://user1:ketiabcs@evc.re.kr:39091/h264Preview_01_main'\n",
    "\n",
    "def view(url):\n",
    "    return writeVideo(url)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=view,\n",
    "    inputs=gr.Textbox(),\n",
    "    outputs=gr.Gallery(),\n",
    "    examples=[\n",
    "        url\n",
    "    ]\n",
    ")\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(server_port=7861)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 저장 송출 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. numpy 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhc/opt/anaconda3/envs/edge-fw/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['out', 'test.mp4']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"video/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'rtsp://user1:ketiabcs@evc.re.kr:39091/h264Preview_01_main'\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeVideo(url, model):\n",
    "    currenttime = datetime.datetime.now()\n",
    "    video_capture = cv2.VideoCapture(url)\n",
    "    \n",
    "    video_capture.set(3, 120)\n",
    "    video_capture.set(4, 120)\n",
    "    fps = 20\n",
    "\n",
    "    streaming_window_width = int(video_capture.get(3))\n",
    "    streaming_window_height = int(video_capture.get(4))\n",
    "\n",
    "    filename = str(currenttime.strftime('%Y %m %d %H %M %S'))\n",
    "    path = os.getcwd() + \"/stream/\" + f\"{filename}.mp4\"\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(path, fourcc, fps, (streaming_window_width, streaming_window_height))\n",
    "\n",
    "    iterating, frame = video_capture.read()\n",
    "    framecnt = 0\n",
    "    imgs = []\n",
    "\n",
    "    while iterating:\n",
    "        results = model(frame)\n",
    "        framecnt += 1\n",
    "        annotated_frame = results[0].plot()\n",
    "        annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        out.write(annotated_frame)\n",
    "        img_arr = np.array(annotated_frame)\n",
    "        imgs.append(img_arr)\n",
    "        \n",
    "\n",
    "        if len(imgs) >= 50:\n",
    "            break\n",
    "\n",
    "    return imgs\n",
    "\n",
    "    video_capture.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = writeVideo(url, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 laptop, 49.6ms\n",
      "Speed: 2.5ms preprocess, 49.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 43.2ms\n",
      "Speed: 1.7ms preprocess, 43.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 66.6ms\n",
      "Speed: 1.7ms preprocess, 66.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 48.6ms\n",
      "Speed: 1.6ms preprocess, 48.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 44.5ms\n",
      "Speed: 1.5ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 65.2ms\n",
      "Speed: 1.7ms preprocess, 65.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 44.5ms\n",
      "Speed: 1.5ms preprocess, 44.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 47.9ms\n",
      "Speed: 1.6ms preprocess, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 46.0ms\n",
      "Speed: 1.6ms preprocess, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 67.6ms\n",
      "Speed: 1.5ms preprocess, 67.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 44.6ms\n",
      "Speed: 1.8ms preprocess, 44.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 56.7ms\n",
      "Speed: 1.7ms preprocess, 56.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 43.0ms\n",
      "Speed: 1.6ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 61.2ms\n",
      "Speed: 1.6ms preprocess, 61.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 44.5ms\n",
      "Speed: 1.5ms preprocess, 44.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 44.7ms\n",
      "Speed: 1.7ms preprocess, 44.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 47.3ms\n",
      "Speed: 1.9ms preprocess, 47.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 42.9ms\n",
      "Speed: 1.8ms preprocess, 42.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 41.9ms\n",
      "Speed: 1.5ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 63.1ms\n",
      "Speed: 1.5ms preprocess, 63.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 55.1ms\n",
      "Speed: 1.7ms preprocess, 55.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 42.4ms\n",
      "Speed: 1.5ms preprocess, 42.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 42.1ms\n",
      "Speed: 1.6ms preprocess, 42.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 45.2ms\n",
      "Speed: 1.5ms preprocess, 45.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 63.0ms\n",
      "Speed: 2.0ms preprocess, 63.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 40.9ms\n",
      "Speed: 1.6ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 42.7ms\n",
      "Speed: 1.6ms preprocess, 42.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 45.5ms\n",
      "Speed: 1.6ms preprocess, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 43.4ms\n",
      "Speed: 1.6ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 63.4ms\n",
      "Speed: 1.6ms preprocess, 63.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 42.4ms\n",
      "Speed: 1.5ms preprocess, 42.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 42.2ms\n",
      "Speed: 2.0ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 44.4ms\n",
      "Speed: 1.6ms preprocess, 44.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 54.2ms\n",
      "Speed: 3.5ms preprocess, 54.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 44.6ms\n",
      "Speed: 1.6ms preprocess, 44.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 41.6ms\n",
      "Speed: 1.7ms preprocess, 41.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 43.9ms\n",
      "Speed: 1.5ms preprocess, 43.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 63.7ms\n",
      "Speed: 1.6ms preprocess, 63.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 43.4ms\n",
      "Speed: 1.7ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 44.2ms\n",
      "Speed: 1.6ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 43.1ms\n",
      "Speed: 1.8ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 41.9ms\n",
      "Speed: 1.8ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 65.6ms\n",
      "Speed: 2.0ms preprocess, 65.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 42.8ms\n",
      "Speed: 1.9ms preprocess, 42.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 40.8ms\n",
      "Speed: 1.5ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 42.4ms\n",
      "Speed: 2.3ms preprocess, 42.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 41.4ms\n",
      "Speed: 2.0ms preprocess, 41.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 laptop, 57.8ms\n",
      "Speed: 4.3ms preprocess, 57.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def show_img():\n",
    "    imgs = writeVideo(url, model)\n",
    "    \n",
    "    for i in imgs:\n",
    "        return Image.fromarray(i)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    out_frame = gr.Image()\n",
    "    btn = gr.Button(value=\"show images\")\n",
    "\n",
    "    btn.click(\n",
    "        show_img,\n",
    "        outputs=out_frame\n",
    "    )\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(server_port=7861)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 로컬 저장 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeVideo(url, model):\n",
    "    currenttime = datetime.datetime.now()\n",
    "    video_capture = cv2.VideoCapture(url)\n",
    "    \n",
    "    video_capture.set(3, 120)\n",
    "    video_capture.set(4, 120)\n",
    "    fps = 20\n",
    "\n",
    "    streaming_window_width = int(video_capture.get(3))\n",
    "    streaming_window_height = int(video_capture.get(4))\n",
    "\n",
    "    filename = str(currenttime.strftime('%Y %m %d %H %M %S'))\n",
    "    path = os.getcwd() + \"/stream/\" + f\"{filename}.mp4\"\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(path, fourcc, fps, (streaming_window_width, streaming_window_height))\n",
    "\n",
    "    iterating, frame = video_capture.read()\n",
    "    framecnt = 0\n",
    "    imgs = []\n",
    "\n",
    "    while iterating:\n",
    "        results = model(frame)\n",
    "        framecnt += 1\n",
    "        annotated_frame = results[0].plot()\n",
    "        annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        out.write(annotated_frame)\n",
    "        img_arr = np.array(annotated_frame)\n",
    "        imgs.append(img_arr)\n",
    "        \n",
    "\n",
    "        if len(imgs) >= 50:\n",
    "            break\n",
    "\n",
    "    return imgs\n",
    "\n",
    "    video_capture.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge-fw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
